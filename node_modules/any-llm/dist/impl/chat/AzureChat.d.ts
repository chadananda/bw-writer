import { ChatBase } from '../../models/Base';
import { ApiKeyValues, ChatMessage, LLMSettings } from '../../models/types';
import { StreamingTextResponse } from 'ai';
import OpenAI from 'openai';
import { Stream } from 'openai/streaming';
export declare class AzureChat extends ChatBase {
    private azureOpenai;
    private apiKeyValues;
    constructor(azureOpenaiApiKey: string, azureOpenaiEndpoint: string, deploymentId: string, apiKeyValues: ApiKeyValues);
    generateChatCompletion(chatSettings: LLMSettings, messages: ChatMessage[]): Promise<Stream<OpenAI.Chat.Completions.ChatCompletionChunk>>;
    generateChatCompletionStream(chatSettings: LLMSettings, messages: ChatMessage[]): Promise<StreamingTextResponse>;
}
