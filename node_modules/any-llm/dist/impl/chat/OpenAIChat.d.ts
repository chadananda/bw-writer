import { ChatBase } from '../../models/Base';
import { ChatMessage, LLMSettings } from '../../models/types';
import { StreamingTextResponse } from 'ai';
import OpenAI from 'openai';
import { ChatCompletionMessageParam } from 'openai/resources';
import { Stream } from 'openai/streaming';
export declare class OpenAIChat extends ChatBase {
    private openai;
    constructor(apiKey: string, baseURL?: string, organization?: string);
    static messageConversion(message: ChatMessage): ChatCompletionMessageParam;
    generateChatCompletion(chatSettings: LLMSettings, messages: ChatMessage[]): Promise<Stream<OpenAI.Chat.Completions.ChatCompletionChunk>>;
    generateChatCompletionStream(chatSettings: LLMSettings, messages: ChatMessage[]): Promise<StreamingTextResponse>;
}
